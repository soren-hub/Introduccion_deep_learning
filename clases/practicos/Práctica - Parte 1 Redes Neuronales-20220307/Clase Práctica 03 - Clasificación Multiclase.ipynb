{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Práctica 03\n",
    "\n",
    "# Neural Network - Redes Neuronales Artificiales\n",
    "\n",
    "# Clasificación Multiclase de Especies Florales\n",
    "\n",
    "En este tutorial de proyecto, descubrirá cómo puede usar Keras para desarrollar y evaluar modelos de redes neuronales para problemas de clasificación de  múltiples clases.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base de datos Iris\n",
    "\n",
    "En este tutorial utilizaremos el conjunto de datos de flores Iris. Este conjunto de datos está bien estudiado y es un buen problema para practicar las redes neuronales porque las 4 variables de entrada son numéricas y tienen la misma escala en centímetros. Cada instancia describe las propiedades de una observación.\n",
    "\n",
    "Las mediciones de flujo y la variable de salida son especies específicas de flores. Los atributos para este conjunto de datos se pueden resumir de la siguiente manera:\n",
    "\n",
    "1. Longitud del sépalo en centímetros.\n",
    "2. Ancho sepal en centímetros.\n",
    "3. Longitud del pétalo en centímetros.\n",
    "4. Ancho del pétalo en centímetros.\n",
    "5. Clase.\n",
    "\n",
    "Este es un problema de clasificación multiclase, lo que significa que hay más de dos clases para predecir, de hecho, hay tres especies de flores. Este es un tipo de problema importante para practicar con redes neuronales porque los tres valores de clase requieren un manejo especializado (manejo de etiquetas). A continuación se observa una muestra de las primeros cinco atributos de las 150 instancias:\n",
    "\n",
    "5.1,3.5,1.4,0.2,Iris-setosa\n",
    "\n",
    "4.9,3.0,1.4,0.2,Iris-setosa\n",
    "\n",
    "4.7,3.2,1.3,0.2,Iris-setosa\n",
    "\n",
    "4.6,3.1,1.5,0.2,Iris-setosa\n",
    "\n",
    "5.0,3.6,1.4,0.2,Iris-setosa\n",
    "\n",
    "\n",
    "La clasificación de la base de datos de Iris es un problema bien estudiado y podemos esperar una precisión del modelo en el rango del 95% al 97%. Esto proporciona un buen objetivo para el desarrollo de nuestros modelos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importar Clases y Funciones\n",
    "\n",
    "Vamos a comenzar importando todas las clases y funciones que necesitaremos para esta práctica. Esto incluye tanto la funcionalidad que requerimos de Keras, como la carga de datos desde Pandas, así como la preparación de datos y la evaluación del modelo desde Scikit-Learn.\n",
    "\n",
    "Además, necesitamos inicializar el generador de números aleatorios (seed) a un valor constante. Esto es importante para garantizar que los resultados que vamos a obtener de este modelo se puedan repetir nuevamente de manera precisa. Esto asegura que el proceso estocástico del entrenamiento de un modelo de red neuronal pueda reproducirse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "# fix random seed for reproducibility\n",
    "seed = 9\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cargar la base de datos Iris\n",
    "\n",
    "El conjunto de datos se puede cargar directamente. Debido a que la variable de salida contiene cadenas (strings), es más fácil cargar los datos utilizando pandas. Luego podemos dividir los atributos (columnas) en variables de entrada (X) y variables de salida (Y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base de datos \n",
    "dataframe = pandas.read_csv(\"iris.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y = dataset[:,4]\n",
    "print(X)\n",
    "print(\"formato de datos de entrada\")\n",
    "print(X.shape)\n",
    "print(\"formato de datos de salida\")\n",
    "print(Y.shape)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codificar las etiquetas de la salida\n",
    "\n",
    "La variable de salida contiene tres valores diferentes (string). Al modelar problemas de clasificación multiclase usando redes neuronales, conviene remodelar el atributo de salida para que sea una matriz con un valor booleano para cada valor de clase. Esto se denomina codificación en caliente (**one hot encoding**) o creación de variables ficticias a partir de una variable categórica. Por ejemplo, en este problema, los tres valores de clase son Iris-setosa, Iris-versicolor e Iris-virginica. Si tuviéramos las tres observaciones:\n",
    "\n",
    "Iris-setosa\n",
    "\n",
    "Iris-versicolor\n",
    "\n",
    "Iris-virginica\n",
    "\n",
    "Podemos convertir las clases en una matriz binaria codificada para cada instancia de datos, esta se vería de la siguiente manera:\n",
    "\n",
    "Iris-setosa, Iris-versicolor, Iris-virginica\n",
    "\n",
    "1,                  0,              0\n",
    "\n",
    "0,                  1,              0\n",
    "\n",
    "0,                  0,              1\n",
    "\n",
    "Podemos realizar esta conversión utilizando la clase LabelEncoder de scikit-learn. Luego se convierte el vector de enteros en una codificación one hot encoding utilizando la función Keras to_categorical().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codificar las clases a integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# convertir clases (one hot encoded)\n",
    "#print(encoded_Y)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "print(\"revise el formato de salida después de aplicar one hot encoded\")\n",
    "print(dummy_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definir el modelo de red neuronal\n",
    "\n",
    "Keras proporciona clases para usar modelos de redes neuronales desarrollados con Keras y Scikit-Learn como vimos en la práctica 2. Hay una clase KerasClassifier en Keras que se puede usar como un Estimador en Scikit-Learn. KerasClassifier toma el nombre de una función como un argumento. Esta función debe devolver el modelo de red neuronal construido, listo para el entrenamiento.\n",
    "\n",
    "A continuación se muestra una función que creará una red neuronal base para el problema de clasificación de la base Iris. Se crea una red simple completamente conectada que contiene 4 entradas con una capa oculta con el mismo número de neuronas (podría ser cualquier número de neuronas). La capa oculta utiliza una función de activación de rectificación (ReLU). Debido a que usamos una codificación one hot para la base de datos de Iris, la capa de salida debe crear 3 valores de salida, uno para cada clase. El valor de salida más grande se tomará como la clase predicha por el modelo. La topología de esta simple red neuronal se puede resumir como:\n",
    "\n",
    "4 inputs -> [4 hidden nodes] -> 3 outputs\n",
    "\n",
    "Se usa una función de activación sigmoide en la capa de salida, para asegurar que los valores de salida estén en el rango de 0 y 1, y se puedan usar como probabilidades pronosticadas. Finalmente, la red utiliza el algoritmo de optimización de descenso por gradiente de ADAM con una función de pérdida logarítmica, que se denomina **crossentropy categórica en Keras para clasificación multiclase**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modelo multiclase\n",
    "def multiclase_model():\n",
    "    # modelo\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=4, init='normal', activation='relu'))\n",
    "    model.add(Dense(3, init='normal', activation='sigmoid'))\n",
    "    # compilar\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) # categorical->multiclase\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimador\n",
    "\n",
    "Ahora podemos crear nuestro KerasClassifier para su uso con Scikit-Learn. También podemos pasar argumentos en la construcción de la clase KerasClassifier que se pasará a la función fit() internamente utilizada para entrenar la red neuronal. Aquí, pasamos el número de épocas como 200 y tamaño de lote como 5 para usar al entrenar el modelo. La depuración también se desactiva cuando se entrena estableciendo verbose en 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = KerasClassifier(build_fn=multiclase_model, epochs=200, batch_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluar el modelo con la validación cruzada k-Fold\n",
    "\n",
    "Ahora podemos evaluar el modelo de red neuronal en nuestros datos de entrenamiento. La biblioteca Scikit-Learn tiene una excelente capacidad para evaluar modelos utilizando un conjunto de técnicas. Una de las técnicas más usada para evaluar modelos de Deep Learning es la validación cruzada k-fold. Primero podemos definir el procedimiento de evaluación del modelo. Aquí, establecemos que el número de carpetas sea 10 y que mezclen los datos antes de particionarlos.\n",
    "\n",
    "Luego podemos evaluar nuestro modelo (estimador) en nuestro conjunto de datos (X y dummy_y) utilizando el procedimiento de validación cruzada (**cross_val_score**) de 10 veces (kfold). La evaluación del modelo solo toma algunos minutos y devuelve un objeto que describe la evaluación de los 10 modelos construidos para cada una de las divisiones del conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Código completo con k-fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "# seed\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# base de datos\n",
    "dataframe = pandas.read_csv(\"iris.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y = dataset[:,4]\n",
    "#print(X)\n",
    "\n",
    "# codificación\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "# (one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "# print(dummy_y)\n",
    "\n",
    "# definir modelos\n",
    "def multiclase_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(4, input_dim=4, init='normal', activation='relu'))\n",
    "    model.add(Dense(3, init='normal', activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "estimator = KerasClassifier(build_fn=multiclase_model, epochs=200, batch_size=5)\n",
    "\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluar el modelo directamente sin k-fold\n",
    "\n",
    "En este ejemplo se muestra como generar una red neuronal que clasifique multiples clases directamente, sin validación cruzada. Sin embargo, se utiliza un porcentaje de los datos de entrenamiento para entrenar y validar la red multiclase creada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerías\n",
    "import numpy\n",
    "import pandas\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# seed\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "\n",
    "# base de datos\n",
    "dataframe = pandas.read_csv(\"iris.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y = dataset[:,4]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=seed) #20% para test\n",
    "\n",
    "# codificación\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "encoded_y_train = encoder.transform(y_train)\n",
    "encoded_y_test = encoder.transform(y_test)\n",
    "# (one hot encoded)\n",
    "dummy_y_train = np_utils.to_categorical(encoded_y_train)\n",
    "dummy_y_test = np_utils.to_categorical(encoded_y_test)\n",
    "\n",
    "# modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(4, input_dim=4, init='normal', activation='relu'))\n",
    "model.add(Dense(3, init='normal', activation='softmax'))\n",
    "# compilar\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# ajuste \n",
    "history = model.fit(X_train, dummy_y_train, validation_data=(X_test,dummy_y_test), nb_epoch=200, batch_size=5, verbose=1) \n",
    "# mostrar los datos que tiene historia\n",
    "#print(history.history.keys())\n",
    "\n",
    "# gráfico para la precisión obtenido de los datos de la historia \n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'ro', label='Acc Entrenamiento')\n",
    "plt.plot(epochs, val_acc, 'b', label='Acc Validación')\n",
    "plt.title('Accuracy: Entrenamiento and Validación')\n",
    "plt.legend()\n",
    "plt.savefig(\"Fig1.png\")\n",
    "\n",
    "# gráfico para la pérdida obtenido de los datos de la historia \n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'ro', label='Loss Entrenamiento')\n",
    "plt.plot(epochs, val_loss, 'b', label='Loss Validación')\n",
    "plt.title('Loss: Entrenamiento and Validación')\n",
    "plt.legend()\n",
    "plt.savefig(\"Fig2.png\")\n",
    "plt.show()\n",
    "\n",
    "# evaluar\n",
    "scores = model.evaluate(X_test,  dummy_y_test)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisión de predicción\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación revisaremos un pequeño ejemplo para realizar la predicción de un dato de entrada. \n",
    "\n",
    "Primero convertiremos la entrada al formato necesario para realizar la predicción usando numpy.reshape(). Recordar que el vector de entrada posee 4 entradas. \n",
    "\n",
    "La predicción realizada se compara con el valor de la etiqueta original. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indice = numpy.random.choice(list(range(len(X_test))), 1)[0]\n",
    "prediccion = model.predict(numpy.reshape(X_test[indice], [1, -1])) # model.predict(numpy.reshape(X[0], (1, 4))) es lo mismo\n",
    "etiqueta_real = dummy_y_test[indice]\n",
    "\n",
    "print(\"Comparación de una predicción aleatoria\")\n",
    "print(\"Valor de la etiqueta real:\")\n",
    "print(etiqueta_real)\n",
    "print(\"Valor de la predicción:\")\n",
    "print(\"se escoge el valor de predicción con mayor valor (probabilidad) para selecionar la clase\")\n",
    "print(prediccion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Matriz de confusión \n",
    "\n",
    "La matriz de confusión se utiliza para describir el rendimiento de un modelo de clasificación en un conjunto de datos de prueba para los que se conocen los valores reales.\n",
    "\n",
    "<img src=\"./images_tutoriales/confusion.png\">\n",
    "\n",
    "\n",
    "La matriz de confusión se compone de diferentes valores conocidos como: verdaderos positivos (TP), negativos verdaderos (TN), Falsos positivos (FP) y Falsos negativos (FN).\n",
    "\n",
    "Positivos verdaderos (TP) : estos son los valores positivos pronosticados correctamente, lo que significa que el valor de la clase real es sí y el valor de la clase pronosticada también es sí. Por ejemplo, si el valor de clase real indica que un pasajero sobrevivió y la clase pronosticada le dice lo mismo.\n",
    "\n",
    "Negativos verdaderos (TN) : estos son los valores negativos predichos correctamente, lo que significa que el valor de la clase real es no y el valor de la clase predicha también es no. Por ejemplo, si la clase real dice que este pasajero no sobrevivió y la clase pronosticada le dice lo mismo.\n",
    "\n",
    "Falsos positivos y falsos negativos, estos valores se producen cuando su clase real se contradice con la clase predicha.\n",
    "\n",
    "Falsos positivos (FP) : cuando la clase real es no y la clase predicha es sí. Por ejemplo, si la clase real dice que este pasajero no sobrevivió pero la clase pronosticada le dice que este pasajero sobrevivirá.\n",
    "\n",
    "Falsos negativos (FN) : cuando la clase real es sí pero la clase predicha es no. Por ejemplo, si el valor real de la clase indica que este pasajero sobrevivió y la clase pronosticada le dice que el pasajero morirá.\n",
    "\n",
    "Con estos cuatro parámetros, podemos calcular el accuracy, la precisión, la recuperación o sensibilidad (recall) y la puntuación de F1 (f1 score).\n",
    "\n",
    "Accuracy (Exactitud): es la medida de rendimiento más intuitiva y es simplemente una proporción de observación pronosticada correctamente con respecto al total de observaciones. Uno puede pensar que, si tenemos una alta accuracy, nuestro modelo es el mejor. El accuracy es una gran medida, pero solo cuando tiene conjuntos de datos simétricos donde los valores de falso positivo y falso negativo son casi iguales. Por lo tanto, debe observar otros parámetros para evaluar el rendimiento de su modelo. \n",
    "\n",
    "Accuracy = TP + TN / (TP + FP + FN + TN)\n",
    "\n",
    "Precisión : precisión es la relación entre las observaciones positivas pronosticadas correctamente y el total de observaciones positivas pronosticadas. La pregunta que responde esta métrica de todos los pasajeros que etiquetaron como sobrevivieron, ¿cuántos sobrevivieron realmente? ¿Qué proporción de identificaciones positivas fue correcta? Alta precisión se relaciona con la baja tasa de falsos positivos. \n",
    "\n",
    "Precisión = TP / (TP + FP)\n",
    "\n",
    "Recall (Recuperación): Recall es la relación entre las observaciones positivas pronosticadas correctamente y todas las observaciones en la clase actual si (yes). La respuesta a la pregunta que se responde es: De todos los pasajeros que realmente sobrevivieron, ¿cuántos etiquetamos correctamente? ¿Qué proporción de positivos reales se identificó correctamente?\n",
    "\n",
    "Recall = TP / (TP + FN)\n",
    "\n",
    "F1 Score (Puntaje F1): El puntaje F1 es el promedio ponderado de Precisión y Recuperación. Por lo tanto, esta puntuación tiene en cuenta tanto los falsos positivos como los falsos negativos. El valor F1 se utiliza para combinar las medidas de precision y recall en un sólo valor. Esto es práctico porque hace más fácil el poder comparar el rendimiento combinado de la precisión y la exhaustividad entre varias soluciones. Intuitivamente, no es tan fácil de entender como la exactitud, pero la F1 suele ser más útil, especialmente si tiene una distribución de clases desigual. La exactitud funciona mejor si los falsos positivos y los falsos negativos tienen un costo similar. Si el costo de los falsos positivos y los falsos negativos es muy diferente, es mejor tener en cuenta tanto la precisión o el recall. \n",
    "\n",
    "Puntuación F1 = 2 * (Recall * Precision) / (Recall + Precision)\n",
    "\n",
    "Por lo tanto, cada vez que construya un modelo, debe analizar estos parámetros para ver que tan bien se ha desempeñado su modelo.\n",
    "\n",
    "Se implementará la matriz de confusión por medio de Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "#Confution Matrix and Classification Report\n",
    "Y_pred = model.predict(X_test)\n",
    "y_pred = numpy.argmax(Y_pred, axis=1)\n",
    "\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(encoded_y_test, y_pred))\n",
    "print('')\n",
    "print('Classification Report')\n",
    "target_names = list(['Iris-setosa','Iris-versicolor', 'Iris-verginica'])\n",
    "print('')\n",
    "print(classification_report(encoded_y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
