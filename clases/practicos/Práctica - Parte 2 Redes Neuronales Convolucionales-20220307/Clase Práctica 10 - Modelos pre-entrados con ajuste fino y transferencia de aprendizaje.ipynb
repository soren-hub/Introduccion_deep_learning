{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Práctica 10\n",
    "\n",
    "# CNN - Redes Neuronales Convolucionales\n",
    "\n",
    "# Modelos pre-entrenados con ajuste fino y transferencia de aprendizaje\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los términos aprendizaje de transferencia y ajuste fino se refieren a dos conceptos que son muy similares en muchos aspectos, y los dos términos se utilizan ampliamente de manera casi intercambiable. Los dos términos no implican el mismo objetivo o motivación, pero aún se refieren a un concepto similar: \n",
    "\n",
    "1) la sintonía precisa o ajuste fino (fine tuning) es tomar un modelo de aprendizaje automático que ya ha aprendido algo antes (es decir, haber sido entrenado en algunos datos) y luego entrenarlo (es decir, entrenarlo un poco más, posiblemente con datos diferentes). Eso es todo lo que significa afinar. \n",
    "\n",
    "2) la transferencia de aprendizaje (transfer learning) significa aplicar el conocimiento que posee un modelo de Deep Learning (representado por sus parámetros aprendidos) a una nueva tarea (pero de alguna manera relacionada). \n",
    "\n",
    "La razón principal por la que las personas utilizan el término ajuste fino es simplemente para indicar que el modelo no se está entrenando desde cero, y que ya se ha entrenado anteriormente en algunos datos (no necesariamente en convergencia). Solo es una forma conveniente de expresar que no estás entrenando desde cero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajuste Fino -  Fine-tuning \n",
    "\n",
    "El motivo principal para usar fine-tuning es el ahorro en recursos de computación y tiempo, pues evitamos la mayor parte del entrenamiento.\n",
    "\n",
    "Si disponemos de acceso a una red pre-entrenada que resuelva un problema similar al que queremos resolver, podemos usar esa red como punto de partida. Simplemente la adaptamos a nuestro problema y continuamos entrenando con nuestros datos. La red ya ha aprendido a extraer las características universales necesarias, por lo que la mayor parte del trabajo ya está hecho.\n",
    "\n",
    "Si disponemos de una red pre-entrenada para un problema similar y disponemos de muchos datos de entrenamiento para nuestro problema concreto, estamos ante el caso ideal. Simplemente usaremos la red pre-entrenada como punto de partida y continuaremos el entrenamiento con nuestros datos.\n",
    "\n",
    "Pero, si tenemos una red pre-entrenada para un problema similar pero tenemos pocos datos de entrenamiento debemos proceder diferente. Entrenar una red con pocos datos nos llevará fácilmente a una situación de overfitting, donde la red aprende a clasificar los datos de entrenamiento pero no los de test (las redes neuronales suelen necesitar muchos datos para poder aprender a generalizar). En este caso entrenaremos solo las últimas capas de la red, congelando el resto. La red ya está entrenada para un problema similar, por lo que la usaremos principalmente como extractor de características.\n",
    "\n",
    "Por otra parte, si disponemos de muchos datos de entrenamiento, la mejor solución suele ser entrenar la red desde cero, aunque esto requiere de mucho tiempo de entrenamiento.\n",
    "\n",
    "Pero si disponemos de pocos datos de entrenamiento la opción anterior no suele ser viable debido al overfitting, a menos que podamos usar con éxito alguna técnica de data augmentation. Ante esta situación, una opción suele ser congelar únicamente las primeras capas de la red. Estas capas han aprendido a extraer características universales por lo que pueden ser aprovechadas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Importando Datos\n",
    "\n",
    "Como de costumbre, debemos cargar las librerias necesarias para poder realizar las tareas de clasificación. En esta parte del código, se muestra como cargar las imagenes de una base de datos. Las imágenes vienen en diferentes directorios (carpetas) y usamos el nombre de cada directorio como nombre de la clase. El código asigna un identificador numérico a cada clase, es decir si hay 5 directorios (carpetas), nuestro código asigna 5 clases (clase: 0, 1, 2, 3, 4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "# parámetros\n",
    "num_classes = 5\n",
    "img_rows, img_cols = 100, 100\n",
    "input_shape = (img_rows, img_cols,3)\n",
    "\n",
    "# función para cargar las imágenes \n",
    "\n",
    "def load_data(path, formato):\n",
    "    class_names={}\n",
    "    class_id=0\n",
    "    Xx = []\n",
    "    Yy = []\n",
    "    for d in glob.glob(os.path.join(path, '*')):\n",
    "        clname = os.path.basename(d)\n",
    "        for f in glob.glob(os.path.join(d, formato)): \n",
    "            if not clname in class_names:\n",
    "                class_names[clname]=class_id \n",
    "                class_id += 1\n",
    "            img = image.load_img(f, target_size=(img_rows, img_cols))\n",
    "            npi = image.img_to_array(img)       \n",
    "            #npi = preprocess_input(npi)\n",
    "            Xx.append(npi)\n",
    "            Yy.append(class_names[clname])\n",
    "    return np.array(Xx), np.array(Yy), class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Cargando la base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar las imágenes, etiquetas y nombres de las clases\n",
    "Xx, Yy, class_names = load_data('flower_photos', '*.jpg')\n",
    "#Xx, Yy, class_names = load_data('profesores', '*.png')\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(\"Las siguientes imágenes fueron exportadas (ejemplos, fila, col, prof) :\")\n",
    "print(Xx.shape)\n",
    "print(\"Las siguientes etiquetas y clases fueron exportadas:\")\n",
    "print(Yy.shape, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_imagen(imagen):\n",
    "    maxi=(np.max(imagen))\n",
    "    mini=(np.min(imagen))\n",
    "    i2 = (imagen-mini)/(maxi-mini)\n",
    "    plt.imshow(i2)\n",
    "\n",
    "normalizar_imagen(Xx[0,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dividiendo las imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(Xx, Yy, test_size=0.1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3)\n",
    "\n",
    "x_train = x_train.astype('float32')/ 255\n",
    "x_val = x_val.astype('float32') / 255 \n",
    "x_test = x_test.astype('float32') /255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_val shape:', x_val.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_val.shape[0], 'val samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(y_train.shape[0], 'train labels')\n",
    "print(y_val.shape[0], 'val labels')\n",
    "print(y_test.shape[0], 'test labels')\n",
    "\n",
    "YY_train=y_train # respaldar variables originales sin hot encoding\n",
    "YY_val=y_val\n",
    "YY_test=y_test\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_val = np_utils.to_categorical(y_val, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "normalizar_imagen(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = x_train[0]\n",
    "print(\"Valores mínimos y máximos de la imagen\")\n",
    "maxi=(np.max(i))\n",
    "mini=(np.min(i))\n",
    "print(mini,maxi )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Redes pre-entrenadas en Keras\n",
    "\n",
    "Keras dispone de diferentes redes pre-entrenadas. En esta tutorial vamos a usar la red convolucional Inception Resnet V2 \n",
    "\n",
    "En esta parte del código se realiza la carga de los pesos de la red pre-entrenada mediante la función InceptionResNetV2() y luego se realiza un procesamiento de los datos de entrada. \n",
    "\n",
    "Es importante destacar el parámetro de la funcion InceptionResNetV2: “include_top=False”. Este parámetro le indica a la red que no debe incluir la última capa de la red, destinada a realizar la predicción final. Esta capa está preparada para realizar las predicciones de todas las clases de ImageNet. Como nosotros queremos predecir únicamente nuestras 5 clases, queremos sustituir esta capa por una capa personalizada. Nuestra red ya no dispone de la última capa, por lo que vamos a añadirle una capa “softmax” de 5 clases. Esto va a permitir que la red haga la predicción de las clases que nos interesan y las entrenadas de ImageNet. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import InceptionResNetV2\n",
    "from keras.applications import VGG16\n",
    "from keras.applications import InceptionV3\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forma secuencial \n",
    "\n",
    "Vamos a usar como modelo base el modelo de la red InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base \n",
    "conv_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "#conv_base = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cabeza\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forma Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base\n",
    "#base_Modelo = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cabeza\n",
    "#head_Modelo = base_Modelo.output\n",
    "#head_Modelo = GlobalAveragePooling2D()(head_Modelo)\n",
    "#head_Modelo = Dense(256, activation=\"relu\")(head_Modelo)\n",
    "#head_Modelo = Dense(num_classes, activation=\"softmax\")(head_Modelo)\n",
    "\n",
    "#model_api = Model(inputs=base_Modelo.input, outputs=head_Modelo)\n",
    "#model_api.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# congelando las capas de la CNN, la cnn base.\n",
    "\n",
    "print('número de capas entrenables de conv base:', len(model.trainable_weights))\n",
    "conv_base.trainable = False\n",
    "print('número de capas entrenables de conv base: ''después de congelar capas de conv base:', len(model.trainable_weights))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compilar Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#model_api.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustar el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochss = range(1, len(acc) + 1)\n",
    "plt.plot(epochss, acc, 'r--o', label='Training acc')\n",
    "plt.plot(epochss, val_acc, 'b--x', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochss, loss, 'r--o', label='Training loss')\n",
    "plt.plot(epochss, val_loss, 'b--x', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"CNN Error: %.2f%%\" % (100-score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#train_datagen = ImageDataGenerator() #rescale=1./255  (la imàgen ya está entre -1 y 1)\n",
    "train_datagen = ImageDataGenerator(rotation_range=45, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "batch_size = 20\n",
    "epochs = 20\n",
    "\n",
    "train_generator = train_datagen.flow(x_train, y_train , batch_size=batch_size)\n",
    "validation_generator = val_datagen.flow(x_val, y_val , batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.random.choice(len(train_generator))\n",
    "img_path = train_generator[index]\n",
    "img = img_path[0]\n",
    "x = img[0,:,:,:]\n",
    "normalizar_imagen(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valores mínimos y máximos de la imagen\")\n",
    "maxi=(np.max(x))\n",
    "mini=(np.min(x))\n",
    "print(mini,maxi )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parámetros del generador\n",
    "steps_per_epoch=x_train.shape[0] // batch_size       \n",
    "validation_steps=x_val.shape[0] // batch_size  \n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit_generator(train_generator, steps_per_epoch=steps_per_epoch, epochs=epochs, validation_data=validation_generator, validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochss = range(1, len(acc) + 1)\n",
    "plt.plot(epochss, acc, 'r--o', label='Training acc')\n",
    "plt.plot(epochss, val_acc, 'b--x', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochss, loss, 'r--o', label='Training loss')\n",
    "plt.plot(epochss, val_loss, 'b--x', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"CNN Error: %.2f%%\" % (100-score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator()\n",
    "test_steps=x_test.shape[0] // batch_size  \n",
    "test_generator = test_datagen.flow(x_test, y_test , batch_size=batch_size)\n",
    "test_loss, test_acc = model.evaluate_generator(test_generator, steps=test_steps)\n",
    "print('test loss:', test_loss)\n",
    "print('test acc:', test_acc)\n",
    "print(\"CNN Error: %.2f%%\" % (100-test_acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Congelar las capas\n",
    "\n",
    "El siguiente paso consiste en decidir que capas congelar. Tendremos que hacer varias pruebas hasta encontrar un número de capas a congelar adecuado. Para tomar la decisión de si un modelo es apropiado o no, consultaremos los datos de validación, no los de test. Los datos de test deben usarse solo al final para ver si el modelo funciona. Tomar decisiones de diseño en base a los resultados en el conjunto de test es un error grave, pues nos lleva a construir una solución que solo funciona con nuestros datos.\n",
    "\n",
    "A continuación vemos como congelar capas (trainable=False). Como nuestro modelo posee 782 capas, vamos a ir modificando este parámetro para ver los porcentajes de clasificación de la red.\n",
    "\n",
    "Otro punto importante es el tiempo dedicado al entrenamiento. Como se puede ver, a medida que se reduce el número de capas congeladas, el tiempo de entrenamiento crece. Por lo que es muy interesante conseguir una red que funcione con muchas capas congeladas. Si se congelan pocas o ninguna ninguna capa, el tiempo de entrenamiento de cada epoch se dispara. Y si lo que se pretende es entrenar la red desde cero, ya es necesario acceder a grandes recursos (Clusters, GPUs, etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAYERS_TO_FREEZE=700\n",
    "for layer in model.layers[:LAYERS_TO_FREEZE]:\n",
    "    layer.trainable = True\n",
    "    \n",
    "model.compile(optimizer=\"adam\",loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochss = range(1, len(acc) + 1)\n",
    "plt.plot(epochss, acc, 'r--o', label='Training acc')\n",
    "plt.plot(epochss, val_acc, 'b--x', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochss, loss, 'r--o', label='Training loss')\n",
    "plt.plot(epochss, val_loss, 'b--x', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"CNN Error: %.2f%%\" % (100-score[1]*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "index = np.random.choice(list(range(len(x_test))), 1)[0]\n",
    "im = x_test[index]\n",
    "target_class = {0:\"Daisy\",1:\"Dandelion\",2:\"Roses\",3:\"Sunflowers\",4:\"Tulips\"}\n",
    "#target_class = {0:\"Esteban\",1:\"Gabriel\",2:\"Gonzalo\",3:\"Héctor\",4:\"Seba\"}\n",
    "\n",
    "print('la imagen de test:')\n",
    "normalizar_imagen(im)\n",
    "\n",
    "print('la clase que predice la red es: ', target_class[np.argmax(model.predict(np.reshape(im, [1,img_rows, img_cols,3])), -1)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# predicciones de nuestra CNN con los datos de test\n",
    "predicted_classes = model.predict_classes(x_test)\n",
    "\n",
    "# revisemos cuales predicciones son correctas e incorrectas\n",
    "correct_indices = np.nonzero(predicted_classes == YY_test)[0]\n",
    "incorrect_indices = np.nonzero(predicted_classes != YY_test)[0]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, correct in enumerate(correct_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    normalizar_imagen(x_test[correct])\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], YY_test[correct]))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    normalizar_imagen(x_test[incorrect])\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], YY_test[incorrect]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de confusión y reportes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score \n",
    "\n",
    "# classification report\n",
    "print('Reporte de Clasificación:')\n",
    "print(classification_report( YY_test,predicted_classes))\n",
    "\n",
    "# confusion matrix \n",
    "cm = confusion_matrix(YY_test,predicted_classes)\n",
    "\n",
    "# mostrar los resultados\n",
    "print('Matriz de confusión:')\n",
    "print(cm)\n",
    "\n",
    "# Print f1, precision, and recall scores\n",
    "print('Precision:')\n",
    "print(precision_score(YY_test, predicted_classes , average=\"macro\"))\n",
    "print('Recall:')\n",
    "print(recall_score(YY_test, predicted_classes , average=\"macro\"))\n",
    "print('F1:')\n",
    "print(f1_score(YY_test, predicted_classes, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
