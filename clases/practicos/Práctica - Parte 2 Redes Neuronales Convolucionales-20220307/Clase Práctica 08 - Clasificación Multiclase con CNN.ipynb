{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clase Práctica 08\n",
    "\n",
    "# CNN - Redes Neuronales Convolucionales\n",
    "\n",
    "# Clasificación multiclase con CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta clase práctica se revisará la forma de cargar una base de datos para realizar la clasificación de imágenes. Para realizar esta tarea, se utilizará un código programado en python, con la librería glob para cargar las imagenes almacenadas en una carpeta. La carpeta debe ser organizada mediante subcarpetas cuyos nombres corresponden a las clases que se quieren clasificar. Una vez que se obtienen los conjuntos de imágenes de validación y test, se procede a crear un modelo de red neuronal convolucional básico para realizar la tarea de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Importando las imágenes \n",
    "\n",
    "Como de costumbre, debemos cargar las librerias necesarias para poder realizar las tareas de clasificación. En esta parte del código, se muestra como cargar las imagenes de una base de datos. Las imágenes vienen en diferentes directorios (carpetas) y usamos el nombre de cada directorio como nombre de la clase. El código asigna un identificador numérico a cada clase, es decir si hay 5 directorios (carpetas), nuestro código asigna 5 clases (clase: 0, 1, 2, 3, 4). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "\n",
    "\n",
    "# parámetros\n",
    "num_classes = 5\n",
    "img_rows, img_cols = 100, 100\n",
    "input_shape = (img_rows, img_cols,3)\n",
    "\n",
    "# función para cargar las imágenes \n",
    "\n",
    "def load_data(path, formato):\n",
    "    class_names={}\n",
    "    class_id=0\n",
    "    Xx = []\n",
    "    Yy = []\n",
    "    for d in glob.glob(os.path.join(path, '*')):\n",
    "        clname = os.path.basename(d)\n",
    "        for f in glob.glob(os.path.join(d, formato)): \n",
    "            if not clname in class_names:\n",
    "                class_names[clname]=class_id \n",
    "                class_id += 1\n",
    "            img = image.load_img(f, target_size=(img_rows, img_cols))\n",
    "            npi = image.img_to_array(img)       \n",
    "            #npi = preprocess_input(npi)\n",
    "            Xx.append(npi)\n",
    "            Yy.append(class_names[clname])\n",
    "    return np.array(Xx), np.array(Yy), class_names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Cargando la base de datos\n",
    "\n",
    "Para cargar las imágenes de la base de datos, llamamos a la función load_data creada en el apartado anterior. Acá asignamos la ruta y el nombre del directorio que contiene las imágenes, además del tipo de datos. Para revisar si se cargaron las imágenes de manera correcta se realiza una visualización de una imagen mediante python. \n",
    "\n",
    "Otra revisión importante es analizar la cantidad de datos obtenidos por nuestra función. Note que la forma de los datos corresponden a (tamaño total de las muestras, dimensión x, dimensión y, profundidad).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargar las imágenes, etiquetas y nombres de las clases\n",
    "Xx, Yy, class_names = load_data('flower_photos', '*.jpg')\n",
    "#Xx, Yy, class_names = load_data('profesores', '*.png')\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(\"Las siguientes imágenes fueron exportadas (ejemplos, fila, col, prof) :\")\n",
    "print(Xx.shape)\n",
    "print(\"Las siguientes etiquetas y clases fueron exportadas:\")\n",
    "print(Yy.shape, len(class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revisando las imágenes cargadas\n",
    "\n",
    "Note que la función plot solo muestra valores entre 0 y 1 adecuadamente. Se observa que la imágen se ve extraña. La razón es la imagen no está en el rango correcto. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Xx[0,:,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = Xx[0,:,:,:]\n",
    "print(\"Valores mínimos y máximos de la imagen\")\n",
    "maxi=(np.max(i))\n",
    "mini=(np.min(i))\n",
    "print(mini,maxi )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a corregir la imágen con una pequeña normalización de rango (0,1). Ahora la imagen se ve como corresponde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2 = (i-mini)/(maxi-mini)\n",
    "plt.imshow(i2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creemos una función para mostrar la imagen corregida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_imagen(imagen):\n",
    "    maxi=(np.max(imagen))\n",
    "    mini=(np.min(imagen))\n",
    "    i2 = (imagen-mini)/(maxi-mini)\n",
    "    plt.imshow(i2)\n",
    "\n",
    "normalizar_imagen(Xx[0,:,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Dividiendo las imágenes\n",
    "\n",
    "En esta parte del código se realiza la división de las imágenes en el conjunto de entrenamiento y test. Utilizamos la función train_test_split para separar los datos. Además, se utiliza la conversión a categorical para obtener una matriz con las clases de manera binaria.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(Xx, Yy, test_size=0.1)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3)\n",
    "\n",
    "x_train = x_train.astype('float32')/ 255\n",
    "x_val = x_val.astype('float32') / 255 \n",
    "x_test = x_test.astype('float32') /255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_val shape:', x_val.shape)\n",
    "print('x_test shape:', x_test.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_val.shape[0], 'val samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print(y_train.shape[0], 'train labels')\n",
    "print(y_val.shape[0], 'val labels')\n",
    "print(y_test.shape[0], 'test labels')\n",
    "\n",
    "YY_train=y_train # respaldar variables originales sin hot encoding\n",
    "YY_val=y_val\n",
    "YY_test=y_test\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_val = np_utils.to_categorical(y_val, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizar_imagen(x_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Modelo de CNN\n",
    "\n",
    "A continuación se define el modelo a utilizar, en este caso un modelo propio y no uno pre entrenado como vimos en el tutorial anterior. \n",
    "\n",
    "Se realizan pruebas de varios modelos de red convolucional para hacer las pruebas de clasificación. Note que por medio de la función model.summary() es posible visualizar el modelo completo que será entrenado con las imagenes de la base de datos propia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.normalization import BatchNormalization\n",
    "# modelo\n",
    "def modelo_cnn():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, kernel_size=(5, 5),activation='relu',input_shape=input_shape))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    #model.add(Dropout(0.50))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = modelo_cnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ajustar la red neuronal convolucional \n",
    "\n",
    "En esta parte del código se realiza el entrenamiento de la red neuronal. Note que se guarda la historia del entrenamiento para poder visualizar el aprendizaje de la red. Recordar que se quiere obtener una minimización de la perdida por lo cual se espera que converja a números cercanos a cero. Además se desea que la validación sea de una manera similar a la curva de entrenamiento, es decir que exista convergencia a números pequeños del loss.  \n",
    "\n",
    "Como resultado nos entrega el error de clasificación y nos entrega la precisión obtenida de los datos de test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs = 20\n",
    "\n",
    "history = model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose=1, validation_data=(x_val, y_val))\n",
    "\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochss = range(1, len(acc) + 1)\n",
    "plt.plot(epochss, acc, 'r--o', label='Training acc')\n",
    "plt.plot(epochss, val_acc, 'b--x', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochss, loss, 'r--o', label='Training loss')\n",
    "plt.plot(epochss, val_loss, 'b--x', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(\"CNN Error: %.2f%%\" % (100-score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validación de la predicción\n",
    "\n",
    "A continuación se detalla como realizar la validación de la predicción mediante una imagen de test. Luego se realiza la predicción multiple de varias imagenes de test con su respectiva clasificación. Para realizar las tareas de predicción, se ejecuta el comando model.predict(). Utilizando el argmax() es posible obtener la clase correspondiente a la imagen de entrada. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "index = np.random.choice(list(range(len(x_test))), 1)[0]\n",
    "im = x_test[index]\n",
    "target_class = {0:\"Daisy\",1:\"Dandelion\",2:\"Roses\",3:\"Sunflowers\",4:\"Tulips\"}\n",
    "#target_class = {0:\"Esteban\",1:\"Gabriel\",2:\"Gonzalo\",3:\"Héctor\",4:\"Seba\"}\n",
    "\n",
    "print('la imagen de test:')\n",
    "normalizar_imagen(im)\n",
    "\n",
    "print('la clase que predice la red es: ', target_class[np.argmax(model.predict(np.reshape(im, [1,img_rows, img_cols,3])), -1)[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# predicciones de nuestra CNN con los datos de test\n",
    "predicted_classes = model.predict_classes(x_test)\n",
    "\n",
    "# revisemos cuales predicciones son correctas e incorrectas\n",
    "correct_indices = np.nonzero(predicted_classes == YY_test)[0]\n",
    "incorrect_indices = np.nonzero(predicted_classes != YY_test)[0]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, correct in enumerate(correct_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    normalizar_imagen(x_test[correct])\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[correct], YY_test[correct]))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "for i, incorrect in enumerate(incorrect_indices[:9]):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    normalizar_imagen(x_test[incorrect])\n",
    "    plt.title(\"Predicted {}, Class {}\".format(predicted_classes[incorrect], YY_test[incorrect]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matriz de confusión y reportes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score \n",
    "\n",
    "# classification report\n",
    "print('Reporte de Clasificación:')\n",
    "print(classification_report( YY_test,predicted_classes))\n",
    "\n",
    "# confusion matrix \n",
    "cm = confusion_matrix(YY_test,predicted_classes)\n",
    "\n",
    "# mostrar los resultados\n",
    "print('Matriz de confusión:')\n",
    "print(cm)\n",
    "\n",
    "# Print f1, precision, and recall scores\n",
    "print('Precision:')\n",
    "print(precision_score(YY_test, predicted_classes , average=\"macro\"))\n",
    "print('Recall:')\n",
    "print(recall_score(YY_test, predicted_classes , average=\"macro\"))\n",
    "print('F1:')\n",
    "print(f1_score(YY_test, predicted_classes, average=\"macro\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
